# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Назначение

Этот репозиторий — инструмент для deep research. Когда пользователь приходит сюда с темой, агент должен:
1. Помочь продумать исследование (thinking partner)
2. Запустить скрипт deep research
3. Сгенерировать PDF с результатами

## Research Workflow

### Фаза 0 — Помощь в продумывании (КРИТИЧНО)

Пользователь может не до конца понимать что именно хочет исследовать. Твоя задача — помочь ему думать:

- Выявить слепые зоны: "Ты упомянул X, но не затронул Y — это намеренно?"
- Предложить неочевидные углы: "Интересно было бы посмотреть на это через призму Z"
- Уточнить границы: "Насколько глубоко копать в сторону A?"
- Проверить assumptions: "Ты исходишь из того что B — это верно для твоего контекста?"
- **ОБЯЗАТЕЛЬНО спросить язык**: "На каком языке нужен результат — русский или английский?"
- **ОБЯЗАТЕЛЬНО спросить processor**: "Какой уровень compute использовать? (pro/ultra/ultra2x)" — предложить на основе сложности темы

Использовать AskUserQuestion для структурированных вопросов. Продолжать диалог пока тема не будет достаточно проработана.

НЕ запускать research сразу — сначала помочь сформулировать правильные вопросы.

**Язык исследования** — КРИТИЧНО уточнять перед запуском. Влияет на:
- Язык brief файла (должен быть на этом языке)
- Язык query к API (должен быть на этом языке + явная инструкция)
- Флаг `--language` при запуске

### Фаза 1 — Создание сессии

```bash
uv run python -m src.main list                           # проверить существующие
uv run python -m src.main create "<тема>"                 # создать новую
```

Запомнить session ID для дальнейших операций.

### Фаза 2 — Запуск Deep Research

**ВАЖНО: Язык и формат**

Brief файл и query должны быть **на языке исследования**.
Query должен начинаться с явной инструкции: `Язык ответа: <язык>.`

1. Создать файл `data/briefs/<session_id>.md` на нужном языке
2. Записать отформатированный запрос в markdown-формате:
   - Первая строка — краткое описание темы
   - Пустая строка
   - Нумерованный список аспектов исследования

Пример brief файла для русского (`data/briefs/<session_id>.md`):
```markdown
Топ-10 покемонов с наибольшим культурным влиянием на Токио.

Исследовать:

1. Покемоны как символы районов Токио
2. Использование в городском брендинге
3. Культовые локации
```

Пример query для русского:
```
Язык ответа: русский.

Топ-10 покемонов, оказавших культурное влияние на Токио. Исследовать: ...
```

Затем запустить скрипт в фоне с `run_in_background: true`:

```bash
uv run python -m src.main research <session_id> "<детальный запрос>" --processor pro --language русский
```

Параметры:
- `<session_id>` — ID сессии (можно partial match)
- `<детальный запрос>` — полный research query на нужном языке
- `--processor` — уровень compute (см. таблицу ниже)
- `--language` — язык исследования для вводной страницы (default: русский)

### Выбор мощности compute (--processor)

| Processor | Время | Цена | Применение |
|-----------|-------|------|------------|
| `lite` | 10s-60s | $5/1k | Базовая метадата, низкая латентность |
| `base` | 15s-100s | $10/1k | Стандартные обогащения |
| `core` | 1-5 мин | $25/1k | Кросс-референсы, умеренная сложность |
| `core2x` | 1-10 мин | $50/1k | Высокая сложность |
| `pro` | 2-10 мин | $100/1k | Exploratory web research (по умолчанию) |
| `ultra` | 5-25 мин | $300/1k | Multi-source deep research |
| `ultra2x` | 5-50 мин | $600/1k | Сложный deep research |
| `ultra4x` | 5-90 мин | $1.2k/1k | Очень сложный deep research |
| `ultra8x` | 5 мин-2 ч | $2.4k/1k | Максимальная глубина |

**Fast-варианты:** К любому процессору можно добавить `-fast` (например `pro-fast`, `ultra-fast`). Fast-варианты оптимизированы по скорости (2-5x быстрее), стандартные — по свежести данных.

**Рекомендации:**
- Быстрый обзор темы → `pro-fast`
- Стандартное исследование → `pro` или `ultra`
- Глубокий анализ со множеством источников → `ultra2x` или выше
- Максимальная глубина для сложных тем → `ultra8x`

Скрипт автоматически:
1. Отправляет запрос в Parallel AI API
2. Ждёт завершения (30-60 минут)
3. Сохраняет результаты в research.json
4. Генерирует PDF в output/reports/

### Фаза 3 — Fork & Continue (КРИТИЧНО)

После запуска research с `run_in_background: true`:

1. **Сообщить пользователю:**
   - Session ID
   - Bash ID фонового процесса
   - Ожидаемое время (~30-60 мин)

2. **НЕ ДЕЛАТЬ:**
   - Не проверять статус автоматически
   - Не polling каждые N секунд
   - Не ждать завершения

3. **СРАЗУ быть готовым к:**
   - Новому исследованию (форк)
   - Другим задачам пользователя
   - Проверке статуса ТОЛЬКО по запросу

### Работа с несколькими исследованиями

Можно запускать несколько исследований параллельно:
- Каждое в своём background bash
- Вести список активных сессий
- Проверять статус только когда пользователь спрашивает

### Проверка статуса (только по запросу)

```bash
uv run python -m src.main show <id>
```

## Команды

```bash
uv run python -m src.main list                                    # список сессий
uv run python -m src.main show <id>                               # детали сессии
uv run python -m src.main create "<тема>"                         # создать сессию
uv run python -m src.main research <id> "<query>" --processor pro --language русский
uv run python -m src.main generate <id>                           # регенерировать PDF
uv run python -m src.main generate <id> --html                    # сгенерировать HTML
DYLD_LIBRARY_PATH=/opt/homebrew/lib uv run python -m src.main generate <id>  # если проблемы с PDF
```

## Переменные окружения

```bash
export PARALLEL_API_KEY="your-api-key"  # Parallel AI API token
```
